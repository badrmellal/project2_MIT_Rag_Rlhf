{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpUFSPf+vzJ6NRjE8L2Kyp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badrmellal/project2_MIT_Rag_Rlhf/blob/main/MitRag%26Rlhf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Project 2: MIT RAG System with RLHF\n",
        "# Author: Badr Mellal & Ilyass Benayed\n",
        "# Date: 27 April 2025\n",
        "\n",
        "---\n",
        "\n",
        "Setup & Imports\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "7POoYNSho1ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q chromadb sentence-transformers transformers ipywidgets==7.7.1 scikit-learn pandas matplotlib seaborn PyPDF2 python-docx tiktoken\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import os, re, time, datetime, uuid, json, sqlite3, tempfile\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Setup environment\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.makedirs(\"/content/data/chroma_db\", exist_ok=True)\n",
        "os.makedirs(\"/content/data/feedback\", exist_ok=True)\n",
        "from google.colab import output, files\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "K5whhRAZo2yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "Document Processing Components\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "b6nNCfIXpBWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MitChunker:\n",
        "    def __init__(self, chunk_size=500, chunk_overlap=100):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "\n",
        "    def split_text(self, text):\n",
        "        if not text:\n",
        "            return []\n",
        "\n",
        "        text_length = len(text)\n",
        "\n",
        "        # Adjust chunk size dynamically\n",
        "        if text_length < 5000:\n",
        "            chunk_size = 400\n",
        "        elif text_length < 15000:\n",
        "            chunk_size = 800\n",
        "        else:\n",
        "            chunk_size = 1200\n",
        "        chunk_overlap = self.chunk_overlap  # Keep overlap as given\n",
        "\n",
        "        paragraphs = re.split(r'\\n\\s*\\n', text)\n",
        "        print(f\"Paragraphs found: {len(paragraphs)}\")  # Moved print up\n",
        "\n",
        "        sections = []\n",
        "\n",
        "        # If badly formatted (1 paragraph = whole text), fallback\n",
        "        if len(paragraphs) <= 1:\n",
        "            for i in range(0, len(text), chunk_size - chunk_overlap):\n",
        "                sections.append(text[i:i+chunk_size])\n",
        "            return sections\n",
        "\n",
        "        current_section, current_length = [], 0\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            if not paragraph.strip():\n",
        "                continue\n",
        "            para_length = len(paragraph)\n",
        "\n",
        "            if current_length + para_length > chunk_size and current_section:\n",
        "                sections.append(\"\\n\\n\".join(current_section))\n",
        "\n",
        "                # Start new section with overlap\n",
        "                overlap_size, overlap_paragraphs = 0, []\n",
        "                for prev_para in reversed(current_section):\n",
        "                    if overlap_size + len(prev_para) <= chunk_overlap:\n",
        "                        overlap_paragraphs.insert(0, prev_para)\n",
        "                        overlap_size += len(prev_para)\n",
        "                    else:\n",
        "                        break\n",
        "                current_section = overlap_paragraphs\n",
        "                current_length = overlap_size\n",
        "\n",
        "            current_section.append(paragraph)\n",
        "            current_length += para_length\n",
        "\n",
        "        if current_section:\n",
        "            sections.append(\"\\n\\n\".join(current_section))\n",
        "\n",
        "        return sections\n",
        "\n",
        "\n",
        "class DocumentProcessor:\n",
        "    def __init__(self, chunk_size=500, chunk_overlap=100):\n",
        "        self.chunker = MitChunker(chunk_size, chunk_overlap)\n",
        "        self.metadata = {}\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        if not text: return \"\"\n",
        "        text = text.replace('\\xa0', ' ')\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\s([.,:;?!])', r'\\1', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def process_pdf(self, file_path):\n",
        "        try:\n",
        "            text, metadata = \"\", {}\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                metadata['pages'] = len(reader.pages)\n",
        "                for page in reader.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        text += page_text + \"\\n\\n\"\n",
        "\n",
        "            self.metadata = metadata\n",
        "            text = self.preprocess_text(text)\n",
        "            chunks = self.chunker.split_text(text)\n",
        "            return text, chunks\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing PDF: {e}\")\n",
        "            return \"\", []\n",
        "\n",
        "    def process_docx(self, file_path):\n",
        "        try:\n",
        "            text, metadata = \"\", {}\n",
        "            doc = Document(file_path)\n",
        "            for para in doc.paragraphs:\n",
        "                if para.text.strip():\n",
        "                    text += para.text.strip() + \"\\n\"\n",
        "\n",
        "            self.metadata = metadata\n",
        "            text = self.preprocess_text(text)\n",
        "            chunks = self.chunker.split_text(text)\n",
        "            return text, chunks\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing DOCX: {e}\")\n",
        "            return \"\", []\n",
        "\n",
        "    def process_text(self, file_path):\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                file_content = file.read()\n",
        "\n",
        "            text = None\n",
        "            for encoding in ['utf-8', 'latin-1', 'windows-1252']:\n",
        "                try:\n",
        "                    text = file_content.decode(encoding)\n",
        "                    break\n",
        "                except UnicodeDecodeError: continue\n",
        "\n",
        "            if text is None:\n",
        "                raise ValueError(\"Could not decode file with any supported encoding\")\n",
        "\n",
        "            self.metadata = {'size': len(file_content), 'format': 'text', 'path': file_path}\n",
        "            text = self.preprocess_text(text)\n",
        "            chunks = self.chunker.split_text(text)\n",
        "            return text, chunks\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing text file: {e}\")\n",
        "            return \"\", []\n",
        "\n",
        "    def process_document(self, file_path=None, file_content=None, file_name=None):\n",
        "        start_time = time.time()\n",
        "        text, chunks = \"\", []\n",
        "\n",
        "        if file_path is not None:\n",
        "            if not os.path.exists(file_path):\n",
        "                return \"\", []\n",
        "\n",
        "            file_extension = Path(file_path).suffix.lower()\n",
        "            file_name = os.path.basename(file_path)\n",
        "\n",
        "            if file_extension == '.pdf':\n",
        "                text, chunks = self.process_pdf(file_path)\n",
        "            elif file_extension in ['.docx', '.doc']:\n",
        "                text, chunks = self.process_docx(file_path)\n",
        "            elif file_extension in ['.txt', '.md']:\n",
        "                text, chunks = self.process_text(file_path)\n",
        "\n",
        "        elif file_content is not None and file_name:\n",
        "            file_extension = Path(file_name).suffix.lower()\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:\n",
        "                temp_file.write(file_content)\n",
        "                temp_path = temp_file.name\n",
        "\n",
        "            if file_extension == '.pdf':\n",
        "                text, chunks = self.process_pdf(temp_path)\n",
        "            elif file_extension in ['.docx', '.doc']:\n",
        "                text, chunks = self.process_docx(temp_path)\n",
        "            elif file_extension in ['.txt', '.md']:\n",
        "                text, chunks = self.process_text(temp_path)\n",
        "\n",
        "            try:\n",
        "                os.unlink(temp_path)\n",
        "            except: pass\n",
        "\n",
        "            self.metadata.update({\"uploaded_filename\": file_name, \"file_size_bytes\": len(file_content)})\n",
        "        else:\n",
        "            return \"\", []\n",
        "\n",
        "        self.metadata.update({\n",
        "            \"filename\": file_name,\n",
        "            \"file_type\": Path(file_name).suffix.lower(),\n",
        "            \"total_chars\": len(text),\n",
        "            \"chunk_count\": len(chunks),\n",
        "            \"processing_timestamp\": datetime.datetime.now().isoformat()\n",
        "        })\n",
        "\n",
        "        return text, chunks"
      ],
      "metadata": {
        "id": "8ehDaz4NpDre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Vector Retrieval System\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WUDlwtHK6-GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MitRetriever:\n",
        "    def __init__(self, collection_name=\"default_collection\",\n",
        "                 model_name='paraphrase-multilingual-MiniLM-L12-v2',\n",
        "                 persist_directory=\"/content/data/chroma_db\"):\n",
        "        self.model_name = model_name\n",
        "        self.collection_name = collection_name\n",
        "        self.persist_directory = persist_directory\n",
        "        self.document_chunks = []\n",
        "        self.chunk_ids = []\n",
        "\n",
        "        # Initialize ChromaDB\n",
        "        self.chroma_client = chromadb.PersistentClient(path=persist_directory)\n",
        "        try:\n",
        "            self.collection = self.chroma_client.get_collection(name=collection_name)\n",
        "            print(f\"Retrieved existing collection '{collection_name}' with {self.collection.count()} documents\")\n",
        "        except:\n",
        "            self.collection = self.chroma_client.create_collection(name=collection_name)\n",
        "            print(f\"Created new collection '{collection_name}'\")\n",
        "\n",
        "        # Initialize embedding model\n",
        "        print(f\"Loading embedding model: {model_name}\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "        # Fallback TF-IDF\n",
        "        self.vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
        "        self.tfidf_matrix = None\n",
        "\n",
        "    def add_documents(self, chunks, metadata=None):\n",
        "        if not chunks: return\n",
        "\n",
        "        self.document_chunks = chunks\n",
        "        self.chunk_ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
        "\n",
        "        if metadata is None:\n",
        "            metadata = [{\"index\": i, \"source\": \"document\"} for i in range(len(chunks))]\n",
        "\n",
        "        # Compute embeddings and add to ChromaDB\n",
        "        print(f\"Computing embeddings for {len(chunks)} chunks...\")\n",
        "        embeddings = self.model.encode(chunks, show_progress_bar=True)\n",
        "        self.collection.add(\n",
        "            embeddings=embeddings.tolist(),\n",
        "            documents=chunks,\n",
        "            ids=self.chunk_ids,\n",
        "            metadatas=metadata\n",
        "        )\n",
        "        print(f\"Added {len(chunks)} chunks to vector database\")\n",
        "\n",
        "        # Also compute TF-IDF as fallback\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(chunks)\n",
        "\n",
        "    def search(self, query, top_k=5):\n",
        "        if not self.document_chunks and self.collection.count() == 0:\n",
        "            return []\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # Try ChromaDB with embeddings\n",
        "        try:\n",
        "            query_embedding = self.model.encode(query).tolist()\n",
        "            chroma_results = self.collection.query(\n",
        "                query_embeddings=query_embedding,\n",
        "                n_results=top_k,\n",
        "                include=[\"documents\", \"distances\", \"metadatas\"]\n",
        "            )\n",
        "\n",
        "            if chroma_results and 'documents' in chroma_results and len(chroma_results['documents']) > 0:\n",
        "                documents = chroma_results['documents'][0]\n",
        "                distances = chroma_results.get('distances', [[]])[0]\n",
        "                metadatas = chroma_results.get('metadatas', [[]])[0]\n",
        "\n",
        "                for i, (doc, distance) in enumerate(zip(documents, distances)):\n",
        "                    metadata = metadatas[i] if i < len(metadatas) else {}\n",
        "                    score = 1.0 - distance if distance < 1.0 else 0.1\n",
        "\n",
        "                    results.append({\n",
        "                        'rank': i + 1,\n",
        "                        'index': metadata.get('index', i),\n",
        "                        'score': score,\n",
        "                        'text': doc,\n",
        "                        'method': 'embedding',\n",
        "                        'metadata': metadata\n",
        "                    })\n",
        "\n",
        "                return results\n",
        "        except Exception as e:\n",
        "            print(f\"Error in embedding search: {e}\")\n",
        "\n",
        "        # Fallback to TF-IDF if needed\n",
        "        if not results and self.tfidf_matrix is not None:\n",
        "            query_vector = self.vectorizer.transform([query])\n",
        "            similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
        "            top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "\n",
        "            for i, idx in enumerate(top_indices):\n",
        "                score = float(similarities[idx])\n",
        "                if score > 0:\n",
        "                    results.append({\n",
        "                        'rank': i + 1,\n",
        "                        'index': int(idx),\n",
        "                        'score': score,\n",
        "                        'text': self.document_chunks[idx],\n",
        "                        'method': 'tfidf'\n",
        "                    })\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "ZzipuAum63XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "LLM Integration\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "CAZjkEvDpTUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HuggingFaceLLM:\n",
        "    def __init__(self, model_name=\"google/flan-t5-base\"):\n",
        "        self.model_name = model_name\n",
        "        try:\n",
        "            print(f\"Loading LLM: {model_name}...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "            self.generator = pipeline(\"text2text-generation\", model=self.model, tokenizer=self.tokenizer, max_length=512)\n",
        "            self.available = True\n",
        "            print(f\"Successfully loaded {model_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            self.available = False\n",
        "\n",
        "    def generate_answer(self, query, contexts):\n",
        "        if not contexts:\n",
        "            return \"No relevant information found to answer this question.\"\n",
        "\n",
        "        # Prepare context\n",
        "        context_text = \"\\n\\n\".join([c['text'] for c in contexts])\n",
        "\n",
        "        # Generate answer with model if available\n",
        "        if self.available:\n",
        "            try:\n",
        "                # Prepare prompt - keep it simple for T5 models\n",
        "                prompt = f\"Answer based on this context: {context_text[:1500]}\\n\\nQuestion: {query}\"\n",
        "\n",
        "                # Generate answer\n",
        "                outputs = self.generator(prompt, max_length=300, do_sample=True, temperature=0.7)\n",
        "                answer = outputs[0]['generated_text']\n",
        "\n",
        "                # Format answer\n",
        "                if len(answer.split()) < 5:  # If too short, use extraction\n",
        "                    return self._extract_answer(query, contexts)\n",
        "\n",
        "                return f\"Based on the document information:\\n\\n{answer}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating with model: {e}\")\n",
        "                return self._extract_answer(query, contexts)\n",
        "        else:\n",
        "            return self._extract_answer(query, contexts)\n",
        "\n",
        "    def _extract_answer(self, query, contexts):\n",
        "        # Simple extraction fallback\n",
        "        if not contexts:\n",
        "            return \"No relevant information found.\"\n",
        "\n",
        "        # Get the most relevant passages\n",
        "        best_context = contexts[0]['text']\n",
        "\n",
        "        # Find sentences that might answer the query\n",
        "        all_text = \" \".join([c['text'] for c in contexts[:3]])\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', all_text)\n",
        "\n",
        "        # Remove common words from query\n",
        "        stop_words = {'the', 'and', 'is', 'in', 'it', 'to', 'of', 'for', 'a', 'on', 'with', 'what', 'how', 'why'}\n",
        "        query_words = set(word.lower() for word in query.split() if word.lower() not in stop_words)\n",
        "\n",
        "        # Score sentences by relevance to query\n",
        "        best_sentences = []\n",
        "        for sentence in sentences:\n",
        "            if not sentence.strip(): continue\n",
        "            sentence_words = set(word.lower() for word in sentence.split())\n",
        "            matching_words = sentence_words.intersection(query_words)\n",
        "            if matching_words:\n",
        "                best_sentences.append((len(matching_words), sentence))\n",
        "\n",
        "        # Sort by relevance\n",
        "        best_sentences.sort(reverse=True)\n",
        "\n",
        "        if best_sentences:\n",
        "            answer_sentences = [s[1] for s in best_sentences[:3]]\n",
        "            return f\"Based on the document information:\\n\\n{' '.join(answer_sentences)}\"\n",
        "        else:\n",
        "            return f\"Based on the document information:\\n\\n{best_context}\""
      ],
      "metadata": {
        "id": "tiyFxepEpX_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Feedback System\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "rWxgtNxp2JOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedbackSystem:\n",
        "    def __init__(self, db_path=\"/content/data/feedback/feedback.db\"):\n",
        "        self.db_path = db_path\n",
        "        os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
        "\n",
        "        # Initialize database\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS feedback (\n",
        "            id TEXT PRIMARY KEY,\n",
        "            query TEXT,\n",
        "            answer TEXT,\n",
        "            context TEXT,\n",
        "            rating INTEGER,\n",
        "            timestamp TEXT,\n",
        "            model TEXT,\n",
        "            retrieval_method TEXT,\n",
        "            metadata TEXT\n",
        "        )\n",
        "        ''')\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def add_feedback(self, query, answer, context, rating, model=\"unknown\", retrieval_method=\"unknown\", metadata=None):\n",
        "        try:\n",
        "            feedback_id = str(uuid.uuid4())\n",
        "            timestamp = datetime.datetime.now().isoformat()\n",
        "            metadata_json = json.dumps(metadata) if metadata else \"{}\"\n",
        "\n",
        "            if isinstance(context, (list, dict)):\n",
        "                context = json.dumps(context)\n",
        "\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute('''\n",
        "            INSERT INTO feedback (id, query, answer, context, rating, timestamp, model, retrieval_method, metadata)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            ''', (feedback_id, query, answer, context, rating, timestamp, model, retrieval_method, metadata_json))\n",
        "            conn.commit()\n",
        "            conn.close()\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error storing feedback: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_feedback_stats(self):\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "\n",
        "            cursor.execute(\"SELECT COUNT(*) FROM feedback\")\n",
        "            total_count = cursor.fetchone()[0]\n",
        "\n",
        "            cursor.execute(\"SELECT AVG(rating) FROM feedback\")\n",
        "            avg_rating = cursor.fetchone()[0]\n",
        "\n",
        "            cursor.execute(\"SELECT rating, COUNT(*) FROM feedback GROUP BY rating\")\n",
        "            rating_dist = dict(cursor.fetchall())\n",
        "\n",
        "            conn.close()\n",
        "\n",
        "            return {\n",
        "                \"total_feedback\": total_count,\n",
        "                \"average_rating\": avg_rating,\n",
        "                \"rating_distribution\": rating_dist\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting feedback stats: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def analyze_feedback(self):\n",
        "        stats = self.get_feedback_stats()\n",
        "        if not stats or stats.get(\"total_feedback\", 0) == 0:\n",
        "            return {\"status\": \"No data\"}\n",
        "\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "\n",
        "            cursor.execute(\"SELECT query, answer, context, rating FROM feedback WHERE rating >= 4\")\n",
        "            high_rated = cursor.fetchall()\n",
        "\n",
        "            cursor.execute(\"SELECT query, answer, context, rating FROM feedback WHERE rating <= 2\")\n",
        "            low_rated = cursor.fetchall()\n",
        "\n",
        "            conn.close()\n",
        "\n",
        "            # Extract insights\n",
        "            insights = []\n",
        "\n",
        "            # Add default insights with limited data\n",
        "            if len(high_rated) < 3 or len(low_rated) < 3:\n",
        "                insights.append(\"Not enough feedback data for detailed analysis\")\n",
        "                if len(high_rated) > len(low_rated):\n",
        "                    insights.append(\"Users seem to prefer more detailed answers\")\n",
        "                if len(low_rated) > len(high_rated):\n",
        "                    insights.append(\"Users prefer more concise answers\")\n",
        "            else:\n",
        "                # Compare answer length\n",
        "                high_lengths = [len(answer) for _, answer, _, _ in high_rated]\n",
        "                low_lengths = [len(answer) for _, answer, _, _ in low_rated]\n",
        "                avg_high = sum(high_lengths) / len(high_lengths)\n",
        "                avg_low = sum(low_lengths) / len(low_lengths)\n",
        "\n",
        "                if avg_high > avg_low * 1.2:\n",
        "                    insights.append(\"Longer answers tend to receive higher ratings\")\n",
        "                elif avg_low > avg_high * 1.2:\n",
        "                    insights.append(\"Shorter, more concise answers tend to receive higher ratings\")\n",
        "\n",
        "            return {\n",
        "                \"total_feedback\": stats[\"total_feedback\"],\n",
        "                \"average_rating\": stats[\"average_rating\"],\n",
        "                \"high_rated_count\": len(high_rated),\n",
        "                \"low_rated_count\": len(low_rated),\n",
        "                \"insights\": insights\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing feedback: {e}\")\n",
        "            return {\"status\": \"Error\", \"message\": str(e)}"
      ],
      "metadata": {
        "id": "O1CjxEec2My5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Main RAG System\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "YK6AkSYupaoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MitRAGSystem:\n",
        "    def __init__(self, collection_name=\"default_collection\", chunk_size=500, chunk_overlap=100,\n",
        "                model_name=\"google/flan-t5-base\", embedding_model=\"paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "                persist_directory=\"/content/data/chroma_db\"):\n",
        "        # Initialize components\n",
        "        self.document_processor = DocumentProcessor(chunk_size, chunk_overlap)\n",
        "        self.retriever = MitRetriever(collection_name, embedding_model, persist_directory)\n",
        "        self.llm = HuggingFaceLLM(model_name)\n",
        "        self.feedback = FeedbackSystem()\n",
        "\n",
        "        # Document information\n",
        "        self.document_text = \"\"\n",
        "        self.document_chunks = []\n",
        "        self.document_name = None\n",
        "        self.document_metadata = {}\n",
        "\n",
        "        # Conversation tracking\n",
        "        self.conversation_history = []\n",
        "\n",
        "        # System metrics\n",
        "        self.metrics = {\n",
        "            'document_processing': [],\n",
        "            'queries': [],\n",
        "            'feedback': []\n",
        "        }\n",
        "\n",
        "        print(f\"MIT RAG System initialized with LLM: {model_name} and Embedding: {embedding_model}\")\n",
        "\n",
        "    def process_document(self, file_path=None, file_content=None, file_name=None):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Process document\n",
        "        text, chunks = self.document_processor.process_document(\n",
        "            file_path=file_path,\n",
        "            file_content=file_content,\n",
        "            file_name=file_name\n",
        "        )\n",
        "\n",
        "        if not chunks:\n",
        "            print(\"No chunks produced from document\")\n",
        "            return False\n",
        "\n",
        "        # Store document info\n",
        "        self.document_text = text\n",
        "        self.document_chunks = chunks\n",
        "        self.document_name = file_name or (file_path and os.path.basename(file_path))\n",
        "        self.document_metadata = self.document_processor.metadata\n",
        "\n",
        "        # Prepare chunk metadata\n",
        "        chunk_metadata = [\n",
        "            {\n",
        "                \"document_name\": self.document_name,\n",
        "                \"chunk_index\": i,\n",
        "                \"document_type\": self.document_metadata.get(\"file_type\", \"unknown\"),\n",
        "                \"source\": \"document\"\n",
        "            } for i in range(len(chunks))\n",
        "        ]\n",
        "\n",
        "        # Add to retriever\n",
        "        self.retriever.add_documents(chunks, metadata=chunk_metadata)\n",
        "\n",
        "        # Track metrics\n",
        "        processing_time = time.time() - start_time\n",
        "        self.metrics['document_processing'].append({\n",
        "            'filename': self.document_name,\n",
        "            'time': processing_time,\n",
        "            'chunks': len(chunks)\n",
        "        })\n",
        "\n",
        "        print(f\"Document processed: {len(chunks)} chunks in {processing_time:.2f}s\")\n",
        "        return True\n",
        "\n",
        "    def answer_question(self, query, top_k=3):\n",
        "        if not self.document_chunks and not hasattr(self.retriever, 'collection'):\n",
        "            return \"Please process a document first.\", [], None\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Retrieve relevant passages\n",
        "        retrieval_results = self.retriever.search(query, top_k=top_k)\n",
        "\n",
        "        if not retrieval_results:\n",
        "            return \"No relevant information found to answer this question.\", [], None\n",
        "\n",
        "        # Generate answer\n",
        "        answer = self.llm.generate_answer(query, retrieval_results)\n",
        "\n",
        "        # Create conversation entry\n",
        "        conversation_id = str(uuid.uuid4())\n",
        "        self.conversation_history.append({\n",
        "            \"id\": conversation_id,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"query\": query,\n",
        "            \"answer\": answer,\n",
        "            \"contexts\": retrieval_results,\n",
        "            \"model\": self.llm.model_name,\n",
        "            \"feedback\": None\n",
        "        })\n",
        "\n",
        "        # Track metrics\n",
        "        total_time = time.time() - start_time\n",
        "        self.metrics['queries'].append({\n",
        "            'query': query,\n",
        "            'time': total_time,\n",
        "            'result_count': len(retrieval_results)\n",
        "        })\n",
        "\n",
        "        return answer, retrieval_results, conversation_id\n",
        "\n",
        "    def add_feedback(self, conversation_id, rating):\n",
        "        # Find conversation entry\n",
        "        entry = next((item for item in self.conversation_history if item[\"id\"] == conversation_id), None)\n",
        "\n",
        "        if not entry:\n",
        "            print(f\"Conversation ID {conversation_id} not found\")\n",
        "            return False\n",
        "\n",
        "        # Update entry with feedback\n",
        "        entry[\"feedback\"] = {\n",
        "            \"rating\": rating,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # Store in feedback database\n",
        "        success = self.feedback.add_feedback(\n",
        "            query=entry[\"query\"],\n",
        "            answer=entry[\"answer\"],\n",
        "            context=[c[\"text\"] for c in entry[\"contexts\"]],\n",
        "            rating=rating,\n",
        "            model=entry[\"model\"],\n",
        "            retrieval_method=entry[\"contexts\"][0][\"method\"] if entry[\"contexts\"] else \"unknown\",\n",
        "            metadata={\"conversation_id\": entry[\"id\"], \"document_name\": self.document_name}\n",
        "        )\n",
        "\n",
        "        # Track metrics\n",
        "        self.metrics['feedback'].append({\n",
        "            'conversation_id': entry[\"id\"],\n",
        "            'query': entry[\"query\"],\n",
        "            'rating': rating\n",
        "        })\n",
        "\n",
        "        return success\n",
        "\n",
        "    def get_document_info(self):\n",
        "        if not self.document_name:\n",
        "            return {\"status\": \"No document processed\"}\n",
        "\n",
        "        return {\n",
        "            \"filename\": self.document_name,\n",
        "            \"chunks\": len(self.document_chunks),\n",
        "            \"total_characters\": len(self.document_text),\n",
        "            **{k: v for k, v in self.document_metadata.items()\n",
        "               if k not in ['processing_timestamp']}\n",
        "        }\n",
        "\n",
        "    def analyze_feedback(self):\n",
        "        return self.feedback.analyze_feedback()"
      ],
      "metadata": {
        "id": "Nkmm9UPYpeim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "UI & Run System\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "RptHb05dpjb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mit_rag_system():\n",
        "    # Initialize system with improved model\n",
        "    rag_system = MitRAGSystem(\n",
        "      collection_name=f\"collection_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "      model_name=\"google/flan-t5-base\",\n",
        "      embedding_model=\"paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "    )\n",
        "\n",
        "    # Output areas\n",
        "    doc_info_output = widgets.Output()\n",
        "    answer_output = widgets.Output()\n",
        "    analytics_output = widgets.Output()\n",
        "\n",
        "    # Create upload button that uses file API directly\n",
        "    upload_button = widgets.Button(\n",
        "        description='Upload Document',\n",
        "        button_style='primary'\n",
        "    )\n",
        "\n",
        "    process_button = widgets.Button(\n",
        "        description='Process Document',\n",
        "        disabled=True,\n",
        "        button_style='primary'\n",
        "    )\n",
        "\n",
        "    # Text display to show uploaded filename\n",
        "    file_text = widgets.HTML(\"No file uploaded\")\n",
        "\n",
        "    # Store the uploaded file\n",
        "    uploaded_file = [None]\n",
        "\n",
        "    # Create query widgets\n",
        "    query_input = widgets.Text(\n",
        "        description='Question:',\n",
        "        placeholder='Ask a question about the document...',\n",
        "        disabled=True,\n",
        "        layout={'width': '80%'}\n",
        "    )\n",
        "\n",
        "    query_button = widgets.Button(\n",
        "        description='Search',\n",
        "        disabled=True,\n",
        "        button_style='success'\n",
        "    )\n",
        "\n",
        "    # Create feedback widgets\n",
        "    feedback_widget = widgets.HBox([\n",
        "        widgets.Label(\"Rate:\"),\n",
        "        widgets.RadioButtons(\n",
        "            options=[('⭐', 1), ('⭐⭐', 2), ('⭐⭐⭐', 3), ('⭐⭐⭐⭐', 4), ('⭐⭐⭐⭐⭐', 5)],\n",
        "            layout={'width': 'max-content'},\n",
        "            disabled=True\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Submit',\n",
        "            disabled=True,\n",
        "            button_style='info',\n",
        "            layout={'width': 'auto'}\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Analytics button\n",
        "    analytics_button = widgets.Button(\n",
        "        description='Show Analytics',\n",
        "        disabled=False,\n",
        "        button_style='info'\n",
        "    )\n",
        "\n",
        "    # Store the current conversation ID\n",
        "    current_conversation_id = [None]\n",
        "\n",
        "    def on_upload_click(b):\n",
        "        try:\n",
        "            clear_output(wait=True)\n",
        "            display(widgets.HTML(\"<h2>MIT RAG System with RLHF</h2>\"))\n",
        "            display(widgets.VBox([\n",
        "                widgets.HBox([upload_button, process_button]),\n",
        "                file_text\n",
        "            ]))\n",
        "            display(doc_info_output)\n",
        "            display(widgets.HTML(\"<h3>Ask a Question</h3>\"))\n",
        "            display(widgets.HBox([query_input, query_button]))\n",
        "            display(answer_output)\n",
        "            display(widgets.HBox([feedback_widget, analytics_button]))\n",
        "            display(analytics_output)\n",
        "\n",
        "            print(\"Please select a file in the pop-up dialog...\")\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            if uploaded:\n",
        "                filename = next(iter(uploaded))\n",
        "                content = uploaded[filename]\n",
        "                file_text.value = f\"<b>Uploaded:</b> {filename} ({len(content)} bytes)\"\n",
        "                uploaded_file[0] = (filename, content)\n",
        "                process_button.disabled = False\n",
        "            else:\n",
        "                file_text.value = \"<b>Upload cancelled or failed</b>\"\n",
        "        except Exception as e:\n",
        "            file_text.value = f\"<b>Error:</b> {str(e)}\"\n",
        "\n",
        "    def on_process_click(b):\n",
        "        doc_info_output.clear_output()\n",
        "        with doc_info_output:\n",
        "            if not uploaded_file[0]:\n",
        "                print(\"Please upload a document first.\")\n",
        "                return\n",
        "\n",
        "            filename, content = uploaded_file[0]\n",
        "            print(f\"Processing: {filename}\")\n",
        "\n",
        "            success = rag_system.process_document(\n",
        "                file_content=content,\n",
        "                file_name=filename\n",
        "            )\n",
        "\n",
        "            if success:\n",
        "                print(\"\\n✅ Document Information:\")\n",
        "                for key, value in rag_system.get_document_info().items():\n",
        "                    print(f\"  {key}: {value}\")\n",
        "                query_input.disabled = False\n",
        "                query_button.disabled = False\n",
        "            else:\n",
        "                print(\"❌ Document processing failed.\")\n",
        "\n",
        "    def on_query_click(b):\n",
        "        answer_output.clear_output()\n",
        "        with answer_output:\n",
        "            query = query_input.value\n",
        "            if not query:\n",
        "                print(\"Please enter a question.\")\n",
        "                return\n",
        "\n",
        "            print(f\"Query: '{query}'\")\n",
        "            answer, results, conversation_id = rag_system.answer_question(query, top_k=3)\n",
        "\n",
        "            current_conversation_id[0] = conversation_id\n",
        "            feedback_widget.children[1].disabled = False\n",
        "            feedback_widget.children[2].disabled = False\n",
        "\n",
        "            print(\"\\nAnswer:\")\n",
        "            print(answer)\n",
        "\n",
        "            print(\"\\nRetrieved passages:\")\n",
        "            for i, result in enumerate(results[:2]):  # Show only top 2 for brevity\n",
        "                print(f\"  Passage {i+1} (Score: {result['score']:.4f})\")\n",
        "                print(f\"  {result['text'][:150]}...\" if len(result['text']) > 150 else f\"  {result['text']}\")\n",
        "\n",
        "    def on_feedback_submit(b):\n",
        "        if current_conversation_id[0] is None:\n",
        "            return\n",
        "\n",
        "        rating = feedback_widget.children[1].value\n",
        "        rag_system.add_feedback(current_conversation_id[0], rating)\n",
        "\n",
        "        feedback_widget.children[1].disabled = True\n",
        "        feedback_widget.children[2].disabled = True\n",
        "\n",
        "        with answer_output:\n",
        "            print(f\"\\n✅ Thank you for your feedback! (Rating: {rating})\")\n",
        "\n",
        "    def on_analytics_click(b):\n",
        "        analytics_output.clear_output()\n",
        "        with analytics_output:\n",
        "            print(\"System Analytics and Feedback\")\n",
        "            print(\"=============================\")\n",
        "\n",
        "            # Plot feedback stats\n",
        "            stats = rag_system.feedback.get_feedback_stats()\n",
        "            if stats and stats.get(\"total_feedback\", 0) > 0:\n",
        "                plt.figure(figsize=(10, 4))\n",
        "                ratings = list(stats[\"rating_distribution\"].keys())\n",
        "                counts = list(stats[\"rating_distribution\"].values())\n",
        "                plt.bar(ratings, counts)\n",
        "                plt.title('Feedback Ratings')\n",
        "                plt.xlabel('Rating')\n",
        "                plt.ylabel('Count')\n",
        "                plt.xticks(range(1, 6))\n",
        "                plt.show()\n",
        "\n",
        "                print(f\"Average Rating: {stats['average_rating']:.2f} ({stats['total_feedback']} ratings)\")\n",
        "            else:\n",
        "                print(\"No feedback data available yet.\")\n",
        "\n",
        "            # Show RLHF analysis\n",
        "            analysis = rag_system.analyze_feedback()\n",
        "            if isinstance(analysis, dict) and \"insights\" in analysis:\n",
        "                print(\"\\nInsights from feedback:\")\n",
        "                for i, insight in enumerate(analysis[\"insights\"]):\n",
        "                    print(f\"{i+1}. {insight}\")\n",
        "            else:\n",
        "                print(\"\\nNot enough feedback data for detailed analysis.\")\n",
        "\n",
        "    # Connect callbacks\n",
        "    upload_button.on_click(on_upload_click)\n",
        "    process_button.on_click(on_process_click)\n",
        "    query_button.on_click(on_query_click)\n",
        "    feedback_widget.children[2].on_click(on_feedback_submit)\n",
        "    analytics_button.on_click(on_analytics_click)\n",
        "\n",
        "    # Display UI\n",
        "    display(widgets.HTML(\"<h2>MIT RAG System with RLHF</h2>\"))\n",
        "    display(widgets.VBox([\n",
        "        widgets.HBox([upload_button, process_button]),\n",
        "        file_text\n",
        "    ]))\n",
        "    display(doc_info_output)\n",
        "    display(widgets.HTML(\"<h3>Ask a Question</h3>\"))\n",
        "    display(widgets.HBox([query_input, query_button]))\n",
        "    display(answer_output)\n",
        "    display(widgets.HBox([feedback_widget, analytics_button]))\n",
        "    display(analytics_output)\n",
        "\n",
        "    return rag_system\n",
        "\n",
        "mit_rag = create_mit_rag_system()"
      ],
      "metadata": {
        "id": "ApoXX7V3poLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}